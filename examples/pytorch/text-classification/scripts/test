#!/bin/bash
#SBATCH --job-name=pruning_fails_distilbert_glue
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --gpus=1
#SBATCH -t 0-5:00:00
#SBATCH --cpus-per-task=18
#SBATCH -o pruning_fails_distilbert_glue.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate transformer


for task in cola sst2 mrpc stsb qqp mnli qnli rte wnli
do
    python run_glue.py \
    --model_name_or_path distilbert-base-cased  --task_name $task  \
    --do_train   --do_eval   --max_seq_length 128   \
    --per_device_train_batch_size 32   --learning_rate 2e-5   --num_train_epochs 3 \
    --output_dir ~/project_space/pruning_fails/distibert/$task/dense/ \
     --fix --sparse_init global_magnitude --sparsity $sparsity

    for sparsity in 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.95 0.98
    do
    python run_glue.py \
    --model_name_or_path distilbert-base-cased  --task_name mrpc  \
    --do_train   --do_eval   --max_seq_length 128   \
    --per_device_train_batch_size 32   --learning_rate 2e-5   --num_train_epochs 3 \
    --output_dir ~/project_space/pruning_fails/distibert/$task/$sparsity \
    --sparse --fix --sparse_init global_magnitude --sparsity $sparsity
    done
done