#!/bin/bash
#SBATCH --job-name=pruning_fails_distilbert_bert_QA_mp
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --gpus=1
#SBATCH -t 1-00:00:00
#SBATCH --cpus-per-task=18
#SBATCH -o pruning_fails_distilbert_bert_QA_mp.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate transformer

for model in bert-base-uncased distilbert-base-uncased
do

for sparsity in 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.95 0.98
do
      python run_qa.py \
          --model_name_or_path $model \
          --dataset_name squad \
          --do_train \
          --do_eval \
          --sparse --fix --sparse_init global_magnitude --sparsity $sparsity \
          --per_device_train_batch_size 12 \
          --learning_rate 3e-5 \
          --num_train_epochs 2 \
          --max_seq_length 384 \
          --doc_stride 128 \
          --output_dir ~/project_space/pruning_fails/QA/$model/global_magnitude/$sparsity
done
done